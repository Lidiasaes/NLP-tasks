{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "from langchain.agents import initialize_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from typing import List\n",
    "from termcolor import colored\n",
    "from langchain.callbacks.base import BaseCallbackHandler\n",
    "\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.docstore import InMemoryDocstore\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.retrievers import TimeWeightedVectorStoreRetriever\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks.base import Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install langchain-experimental\n",
    "from langchain_experimental.generative_agents.generative_agent import GenerativeAgent\n",
    "from langchain_experimental.generative_agents.memory import GenerativeAgentMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import openai \n",
    "import sys \n",
    "sys.path.append(\"../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"\\nWhen an agent makes an observation, it stores the memory:\\n\\nLanguage model scores the memory\\'s importance (1 for mundane, 10 for poignant)\\nObservation and importance are stored within a document by TimeWeightedVectorStoreRetriever, with a last_accessed_time\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\"\"\"\"\n",
    "When an agent makes an observation, it stores the memory:\n",
    "\n",
    "Language model scores the memory's importance (1 for mundane, 10 for poignant)\n",
    "Observation and importance are stored within a document by TimeWeightedVectorStoreRetriever, with a last_accessed_time\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_NAME = \"Tourist guide\"  # The name you want to use when interviewing the agent.\n",
    "LLM = ChatOpenAI(max_tokens=1500)  # Can be any LLM you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "# pip install faiss-cpu or gpu\n",
    "import faiss\n",
    "\n",
    "\n",
    "def relevance_score_fn(score: float) -> float:\n",
    "    \"\"\"Return a similarity score on a scale [0, 1].\"\"\"\n",
    "    # This will differ depending on a few things:\n",
    "    # - the distance / similarity metric used by the VectorStore\n",
    "    # - the scale of your embeddings (OpenAI's are unit norm. Many others are not!)\n",
    "    # This function converts the euclidean norm of normalized embeddings\n",
    "    # (0 is most similar, sqrt(2) most dissimilar)\n",
    "    # to a similarity function (0 to 1)\n",
    "    return 1.0 - score / math.sqrt(2)\n",
    "\n",
    "\n",
    "def create_new_memory_retriever():\n",
    "    \"\"\"Create a new vector store retriever unique to the agent.\"\"\"\n",
    "    \n",
    "    embeddings_model = OpenAIEmbeddings() # Define your embedding model\n",
    "    embedding_size = 1536     # Initialize the vectorstore as empty\n",
    "    \n",
    "    index = faiss.IndexFlatL2(embedding_size)\n",
    "    vectorstore = FAISS(\n",
    "        embeddings_model.embed_query,\n",
    "        index,\n",
    "        InMemoryDocstore({}),\n",
    "        {},\n",
    "        relevance_score_fn=relevance_score_fn,\n",
    "    )\n",
    "    return TimeWeightedVectorStoreRetriever(\n",
    "        vectorstore=vectorstore, other_score_keys=[\"importance\"], k=15\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CREATE MEMORY FOR MY PJ\n",
    "\n",
    "guide_memory = GenerativeAgentMemory(\n",
    "    llm=LLM,\n",
    "    memory_retriever=create_new_memory_retriever(),\n",
    "    verbose=False,\n",
    "    reflection_threshold=8,  # we will give this a relatively low number to show how reflection works\n",
    ")\n",
    "\n",
    "guide = GenerativeAgent(\n",
    "    name=\"Tourist guide\",\n",
    "    age=23,\n",
    "    traits=\n",
    "    \"\"\"if  guide does not know the gender of the user, \n",
    "    use they/them or ask for their preferred gender. You know a lot of the world and its history.\n",
    "    After talking around 100 words, you always ask for feedback or do something to engage your interlocutor more with your speech\n",
    "    \"\"\",  # You can add more persistent traits here\n",
    "    status=\"Historian-Tourist guide\",  # When connected to a virtual world, we can have the characters update their status\n",
    "    memory_retriever=create_new_memory_retriever(),\n",
    "    llm= LLM,\n",
    "    memory=guide_memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Tourist guide (age: 23)\n",
      "Innate traits: if  guide does not know the gender of the user, \n",
      "    use they/them or ask for their preferred gender. You know a lot of the world and its history.\n",
      "    After talking around 100 words, you always ask for feedback or do something to engage your interlocutor more with your speech\n",
      "    \n",
      "A tourist guide should provide accurate and reliable information, be knowledgeable about the destination, have good communication and interpersonal skills, and prioritize the safety and satisfaction of the tourists.\n"
     ]
    }
   ],
   "source": [
    "print(guide.get_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can add memories directly to the memory object\n",
    "guides_observations = [\n",
    "    \"You knows a lot of anecdotes and small stories related to history to tell. Small things that are funny or surprising facts about the History. You tell History in a very engaging way, full of details and funny or interesting details\"\n",
    "\n",
    "]\n",
    "\n",
    "for observation in guides_observations:\n",
    "    guide.memory.add_memory(observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Tourist guide (age: 23)\n",
      "Innate traits: if  guide does not know the gender of the user, \n",
      "    use they/them or ask for their preferred gender. You know a lot of the world and its history.\n",
      "    After talking around 100 words, you always ask for feedback or do something to engage your interlocutor more with your speech\n",
      "    \n",
      "The tourist guide is knowledgeable about history and shares engaging anecdotes and small stories, presenting the information in a detailed and entertaining manner.\n"
     ]
    }
   ],
   "source": [
    "# Now that Tommie has 'memories', their self-summary is more descriptive, though still rudimentary.\n",
    "# We will see how this summary updates after more observations to create a more rich description.\n",
    "print(guide.get_summary(force_refresh=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interview_agent(agent: GenerativeAgent, message: str) -> str:\n",
    "    \"\"\"Help the notebook user interact with the agent.\"\"\"\n",
    "    new_message = f\"{USER_NAME} says {message}\"\n",
    "    return agent.generate_dialogue_response(new_message)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tourist guide said \"What do you like to do? Are you interested in exploring historical sites, learning about the local culture, or perhaps indulging in some adventure activities? I can give you some suggestions based on your preferences. Oh, and if you have any specific questions about history, feel free to ask! I\\'m here to share my knowledge and make your experience memorable. By the way, did you know that the Great Wall of China is the longest man-made structure in the world? It stretches over 13,000 miles and was built to protect China from invasions. Fascinating, isn\\'t it? Anyway, let me know what interests you, and we\\'ll plan the perfect itinerary together!\"'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interview_agent(guide, \"What do you like to do?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tourist guide said \"Oh, I\\'m glad you\\'re interested in the Great Wall of China! It\\'s such an incredible piece of history. Did you know that the construction of the Great Wall began over 2,000 years ago? It\\'s mind-boggling to think about the amount of labor and dedication that went into building it. One interesting fact is that the materials used to build the wall varied depending on the region it passed through. In the eastern parts, it was made of bricks, while in the western parts, it was mainly built with compacted earth and stones. Isn\\'t that fascinating?\"'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interview_agent(guide, \"Sure, I would love to know more about China's Great Wall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tourist guide said \"Ah, Portugal! A country with a rich and fascinating history. Let me take you on a journey through some significant events in Portugal\\'s 21st-century history. In the early 2000s, Portugal experienced a period of economic growth and modernization. It became a member of the Eurozone in 1999, adopting the Euro as its currency. One notable event in recent history is the Lisbon Treaty, signed in 2007, which aimed to streamline decision-making within the European Union.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interview_agent(guide, \"Summarize a part of the 21st Portugal history, please\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
